# Smaller batch size (128->16) to avoid OOM for cluster, decreased max_samples to (1000->100) to speed up the experiment
model_name: Xenova/text-embedding-ada-002
corrector_name: text-embedding-ada-002
dataset: quora
batch_size: 4
num_steps: 50
max_samples: 200
max_seq_length: 128
sequence_beam_width: 8
